---
title: "Statistical Learning (5454) - Assignment 3"  
author: "Matthias Hochholzer, Lukas Pirnbacher, Anne Valder"
date: "Due: 2024-05-20"
output: 
  pdf_document: 
    keep_tex: yes
header-includes:
   - \usepackage{titlesec}
   - \titleformat*{\section}{\normalfont\Large\bfseries\flushleft}
   - \titleformat*{\subsection}{\normalfont\large\bfseries\flushleft}
   - \titleformat*{\subsubsection}{\normalfont\normalsize\bfseries\flushleft}
   - \usepackage{amsmath}
   - \newcommand*{\defeq}{\mathrel{\vcenter{\baselineskip0.5ex \lineskiplimit0pt
                     \hbox{\scriptsize.}\hbox{\scriptsize.}}}=}
   - \newcommand*{\eqdef}{=\mathrel{\vcenter{\baselineskip0.5ex \lineskiplimit0pt
                     \hbox{\scriptsize.}\hbox{\scriptsize.}}}}
                     
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
```


```{r,include=FALSE}
# Clear memory
rm(list=ls())
```

```{r, echo=FALSE, include=FALSE, warning=FALSE}


```



<!-- EXERCISE 1 -->
# Exercise 1
We load the data set \textit{Carseats} from package \textit{ISLR2}. We then split the data set into a training set and a test set.
```{r}
data("Carseats", package = "ISLR2")

set.seed(123) # set the seed

train_index <- sample(seq_len(nrow(Carseats)), size = 100)
train <- Carseats[train_index,]
test <- Carseats[-train_index,]

X_train <- as.matrix(train[,-1]) # covariates of sample
y_train <- train[,1] # dependent variable of sample
X_test <- as.matrix(test[,-1]) # covariates of test
y_test <- test[,1] # dependent variable of test

```

We fit a regression tree to the training set. 
```{r}
library(rpart)

tree <- rpart(Sales ~ ., data =train, 
  method = "anova", parms = list(split = "gini"), # regression tree
  control = list(cp = 0.0001))
options(digits = 4, width= 60)
printcp(tree)

```
The plot of the tree is seen below.
```{r}
# plotcp(tree)

library("partykit")
tree_party <- partykit::as.party(tree)
plot(tree_party)

```

The test MSE is
```{r}
tree_fit <- predict(tree, newdata = test)

MSE <- function(y_hat){
error <- mean((y_hat-y_test)^2)
return(error)
}

MSE(tree_fit)
```

```{r}
imin <- which.min(tree$cptable[, "xerror"])
select <- which(
  tree$cptable[, "xerror"] < 
    sum(tree$cptable[imin, c("xerror", "xstd")]))[1]
ptree <- prune(tree, cp = tree$cptable[select, "CP"])

# plotcp(ptree)

ptree_party <- partykit::as.party(tree)
plot(ptree_party)

```

The test MSE with pruning is
```{r}
ptree_fit <- predict(ptree, newdata = test)

MSE(ptree_fit)
```

<!-- EXERCISE 2 -->

# Exercise 2
We draw 100 observations from fourindependentvariables $X_1$, ... ,$X_4$ where
\begin{itemize}
  \item $X_1$ follows a uniform distribution,
  \item $X_2$ follows a standard normal distribution,
  \item $X_3$ follows a Bernoulli distribution with success probability $\pi$ = 0.5,
  \item $X_4$ follows a Bernoulli distribution with success probability $\pi$ = 0.1.
\end{itemize}

```{r}
rm(list=ls())
set.seed(123) # set the seed

n <- 100
X1 <- runif(n)
X2 <- rnorm(n)
X3 <- rbinom(n,1,0.5)
X4 <- rbinom(n,1,0.1)
X <- cbind(X1,X2,X3,X4)


```


We repeat 1000 times the following:
\begin{itemize}
  \item Draw a dependent variable y from a standard normal distribution which is independent of the four independent variables.
  \item Fit a tree stump, i.e., a tree which contains only one split.
  \item Determine which variable was used for splitting.
\end{itemize}

Create the table of relative frequencies how often each of the variables was selected for splitting. Given that
all independent variables are not associated with the dependent variable, is the probability of including them
as a split variable the same? If not, why would they differ?

```{r}

helpf <- function(x){
y <- rnorm(100)
data <- data.frame(cbind(y,x))
tree <- rpart(y ~ ., data = data, method = "anova",
control = list(maxdepth = 1, cp =-1))
variable <- names(which.max(tree$variable.importance))
return(variable)
}
reps <- replicate(1000, helpf(X))


rel_freq <- table(factor(reps,levels=c("X1","X2","X3","X4")))/length(reps)
rel_freq
barplot(rel_freq)
```


<!-- EXERCISE 3 -->
# Exercise 3

Let's assume the following data generating process
$$ Y = X + \epsilon, $$
with $X \sim N(0,1)$ and $\epsilon \sim N(0,1)$ independent.
In addition 20 covariates $Z_1, ... ,Z_{20}$ are given with
$$Z_i \sim \sqrt{0.9}X + \epsilon Z_i ,$$
where $\epsilon Z_i \sim N(0, 0.1).$


We draw a training data with 30 observations and a test data with 10,000 observations from the data generating
process including the additional covariates \textbf{Z}.

```{r}
rm(list=ls())
set.seed(123) # set the seed

X_train <- rnorm(30,0,1)
eps_train <- rnorm(30,0,1)
Y_train <- X_train + eps_train

help_cov <- function(Z){
X <- rnorm(20)
for(i in 1:20){
  Z[i] <- sqrt(0.9) * X[i] + rnorm(1, 0, 0.1)
}
return(Z)
}

Z_train <- as.data.frame(t(replicate(30, help_cov(20))))
train <- as.data.frame(cbind(Y_train, X_train, Z_train))
colnames(train) <- c("Y", "X", paste("Z_",1:20))



X_test <- rnorm(10000,0,1)
eps_test <- rnorm(10000,0,1)
Y_test <- X_test + eps_test
Z_test <- as.data.frame(t(replicate(1000, help_cov(20))))
test <- as.data.frame(cbind(Y_test, X_test, Z_test))
colnames(test) <- c("Y", "X", paste("Z_",1:20))
```

We sample 100 bootstrap samples of size 30 from the training data of the previous example by drawing with
replacement.

```{r}


bsample <- list()


for(i in 1:100) {
  index <- sample(1:nrow(train), size = 30, replace = TRUE)
  
  bootstrap <- train[index, ]

  bsample[[i]] <- bootstrap
}

```

Fit to each bootstrap sample: 
\begin{enumerate}
\item a regression tree,
\item the null model with predicted value equal to the observed empirical mean of Y ,
\item a linear model including linear effects for X and all Z variables and
\item a linear model potentially including linear effects for X and all Z variables, but using model selection
with the AIC to select a suitable model starting from the null model.
\end{enumerate}

```{r include=FALSE}
library(rpart)
library(MASS)

btree <- list() # Creating empty vectors for the results
bnull <- list()
blm <- list()
bAIC <- list()

for(i in 1:100) {
  btree[[i]] <- rpart(Y ~ ., data = bsample[[i]],
                method = "anova", control = list(cp = 0.0001))
  bnull[[i]] <- lm(Y ~ 1, data = bsample[[i]])
  blm[[i]] <- lm(Y ~ ., data = bsample[[i]])
  bAIC[[i]] <- stepAIC(bnull[[i]], direction = "both",
                scope = list(upper = blm[[i]],
                lower = bnull[[i]], k = 2, trace = FALSE))
}

```


Determine the predicted values on the test data for the bagged model estimator by calculating the average
predictions over the 100 trees fitted to the bootstrap samples, the 100 null models, the 100 linear models
including all linear effects and the 100 linear models based on model selection.

```{r warning=FALSE, include=FALSE}

fit_tree <- list()
fit_null <- list()
fit_lm <- list()
fit_AIC <- list()

for(i in 1:100) {
  fit_tree[[i]] <- predict(btree[[i]], newdata = test)
  fit_null[[i]] <- predict(bnull[[i]], newdata = test)
  fit_lm[[i]] <- predict(blm[[i]], newdata = test)
  fit_AIC[[i]] <- predict(bAIC[[i]], newdata = test)
}

```

```{r}
mean_tree <- mean(unlist(fit_tree))
mean_null <- mean(unlist(fit_null))
mean_lm <- mean(unlist(fit_lm))
mean_AIC <- mean(unlist(fit_AIC))

means <- data.frame(
  Model = c("Tree", "Null", "LM", "AIC"),
  Mean = c(mean_tree, mean_null, mean_lm, mean_AIC)
)
means
```


Last, we determine the mean squared error of the four bagged model estimators on the test sample of size 10,000.

```{r}

MSE <- function(Y_hat){
error <- mean((Y_hat-Y_test)^2)
return(error)
}

MSE_tree <- MSE(mean_tree)
MSE_null <- MSE(mean_null)
MSE_lm <- MSE(mean_lm)
MSE_AIC <- MSE(mean_AIC)

MSEs <- data.frame(
  Model = c("Tree", "Null", "LM", "AIC"),
  MSE = c(MSE_tree, MSE_null, MSE_lm, MSE_AIC)
)
MSEs

```



<!-- EXERCISE 4 -->
# Exercise 4

We load the dataset icu in package \textbf{aplore3} which contains information on patients who were admitted to an adult intensive care
unit (ICU). We develop a predictive model for the probability of survival to hospital discharge of these
patients. To fit a predictive model to the data we use random forests.

```{r}
rm(list=ls())
set.seed(123)
data("icu", package = "aplore3")
```
We select a suitable number of bootstrap iterations.

```{r}

```

Assess the influence of varying the hyperparameter m on the out-of-bag error obtained and select a suitable
value.
```{r}

```

Inspect the variable importance measures. Compare the mean decrease Gini and the mean decrease accuracy
measures and assess if the observed differences in relative importance assigned might be related to the
predictor variable being numeric or not.

```{r}

```


<!-- EXERCISE 5 -->
# Exercise 5

Assume that there are four predictor variables which have the following distributions:

\begin{align}
X_1 \sim N(0, 1),&& &X_2 \sim U(0, 1), \\
X_3 \sim M(1, (0.5, 0.5)),&& &X_4 \sim M(1, (0.2, 0.2, 0.2, 0.2, 0.2)).
\end{align} 

This means we have two continuous variables which follow either a standard normal or a standard uniform
distribution ($U(0, 1)$ and two categorical variables with balanced categories with either 2 or 5 categories, i.e.,
$M(N, \pi)$ is the multinomial distribution for N trials and success probability vector $\pi$.
The dependent variable y is assumed to be a binary categorical variable with equal-sized classes.The sample size is set to N = 200.


We generate 100 datasets for each setting and fit a random forest to each dataset and determine the mean
decrease Gini and mean decrease accuracy values for each of the predictor variables.
```{r}
rm(list=ls())
set.seed(123)
library(randomForest)
```

Let's suitably visualize the results and interpret them.

```{r}

```

