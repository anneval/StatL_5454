# ===========================================================================================================
# 0. INITIALIZATION
# ===========================================================================================================
# Clear all
rm(list = ls())
set.seed(1234)
# Set paths
path <- 'C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/'
setwd(path)
paths <- list(pro = "00_prog",
dat = "10_data",
fig = "20_figures",
tab = "30_tables",
too = "40_tools",
rst = "50_results")
# Install needed packages
myPKGs <- c('torch', 'pracma','glmnet','ranger',
'ggplot2','reshape2', 'stringr','MacroRF',
'caret','doParallel','gridExtra','gbm')
InstalledPKGs <- names(installed.packages()[,'Package'])
InstallThesePKGs <- myPKGs[!myPKGs %in% InstalledPKGs]
if (length(InstallThesePKGs) > 0) install.packages(InstallThesePKGs, repos = "http://cran.us.r-project.org")
# Load libraries
library(torch)      # Neural Networks
library(glmnet)     # Lasso, Ridge and Elastic-Net
library(ranger)     # Random Forest
library(MacroRF)    # Macro Random Forest
library(caret)      # Gradient boosting machine (GBM)
library(ggplot2)    # Graphs
library(reshape2)   # Data manipulation
library(gridExtra)  # To organize results graphs
library(pracma)     # Utilities (for PCA)
library(stringr)    # String manipulation
library(doParallel) # Parallel estimation
library(foreach)    # Parallel estimation
# If you are installing "torch" for the first time, you must use the following functions :
# install_torch()
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
# Factor analysis (PCA)
source(paste(paths$too, 'EM_sw.R', sep='/'))
source(paste(paths$too, 'factor.R', sep='/'))
source(paste(paths$too, 'ICp2.R', sep='/'))
# Neural Network function
source(paste(paths$too, 'MLP_function_v6b.R', sep='/'))
# Out-of-sample functions
source(paste(paths$pro, 'OOS_models.R', sep='/'))
# Number of CPU for the estimation (if you don't want to use the parallel setting : ncores <- NA)
ncores <- 4
torch_set_num_threads(1)
# ===========================================================================================================
# 1. OUT-OF-SAMPLE AND MODEL'S PARAMETERS
# ===========================================================================================================
## OOS Parameters ----------------------------------------------------------------
OOS_params <- list()
# Target names from FRED DB
# OOS_params$targetName <- c("CPIAUCSL","UNRATE",
#                            "HOUST", "PAYEMS",
#                            "GDPC1")
OOS_params$targetName <- c("CPI_ALL")
# Change the transformation code of the target, "NA" to keep FRED's code
OOS_params$target_tcode <- c(NA) # not really needed here since we use the balanced UK data set
# Forecasting horizons (in quarter), month here
OOS_params$horizon <- c(3,12)
#OOS_params$horizon <- c(1,3,12)
# Out-of-sample starting date
OOS_params$OOS_starting_date <- "2015-01-01"
# Number of FRED's factors
OOS_params$nFac <- 8
# Number of target lags
OOS_params$lagY <- 6
# Number of regressors lags (factors included)
OOS_params$lagX <- 6
# Create MARX
OOS_params$lagMARX <- NA
# Number of folds for CV
OOS_params$nfolds <- 5
# How many quarters between hyperparameters CV (in quarters)
OOS_params$reEstimate <- 60 # each 5 years
# Which models to used ? Possible choice c("AR, BIC", "ARDI, BIC","LASSO","RIDGE","ELASTIC-NET","RF","GBM","NN,"AR-RF")
#OOS_params$model_list <- c("AR, BIC", "ARDI, BIC","LASSO","RIDGE","RF","GBM","NN","AR-RF")
OOS_params$model_list <- c("AR, BIC","RF","AR-RF","RF-MAF","FA-ARRF") #RF_MAF, RF, FA-ARRF
# Folder name in 50_results
OOS_params$save_path = "demo"
## Hyperparamters ----------------------------------------------------------------
# Elastic - Net hyperparameters (CV)
#OOS_params$EN_hyps <- list(alpha_range = round(seq(0.01,0.99, length = 100),4))
# Boosting hyperparameters (CV)
# OOS_params$Boosting_hyps <- list(man_grid = expand.grid(n.trees = c(seq(25, 700, by = 100)),
#                                                         interaction.depth = c(3,5),
#                                                         shrinkage = c(0.01),
#                                                         n.minobsinnode = c(10)),
#                                  fitControl = trainControl(method = "cv",
#                                                            number = OOS_params$nfolds,
#                                                            search = "grid"))
# Random Forest a) hyperparameters
OOS_params$RF_hyps <- list(num.trees = 500,
min.node.size = 3,
mtry = 1/3)
# Random Forest b) hyperparameters
OOS_params$RF_MAF_hyps <- list(num.trees = 500,
min.node.size = 3,
mtry = 1/3)
# Macro Random Forest hyperparamaters
OOS_params$MacroRF_hyps <- list(x_pos = c(2,3,4,5,6,7), #### für den ARRF & month lags i.e. 2 Quarter before now monthly
B = 50,
mtry_frac = 0.15,
minsize = 15,
block_size = 24) # block size is 24 in monthly i.e. 2 years
# Macro Random Forest hyperparamaters
OOS_params$FA_MacroRF_hyps <- list(x_pos = c(2,3,4,5,6,7,26,27), #### für den ARRF & month lags i.e. 2 Quarter before now monthly
B = 50,
mtry_frac = 0.15,
minsize = 15,
block_size = 24) # block size is 24 in monthly i.e. 2 years
# Neural network hyperparameters
# OOS_params$nn_hyps <- list(n_features=NA,
#                            nodes=rep(100,5),      # same number of nodes in every layers
#                            patience=10,           # Return the best model
#                            epochs=100,
#                            lr=0.001,
#                            tol=0.01,
#                            show_train=3,          # 1=show each bootstrap loss, 2=progress bar, 3+=show nothing
#                            num_average=5,
#                            dropout_rate=0.2,
#                            sampling_rate = 0.75,
#                            batch_size = 32,
#                            num_batches = NA)
# ===========================================================================================================
# 2. PARALLEL ESTIMATION
# ===========================================================================================================
# Create all possible of targets and horizons
combn <- list(var = c(1:length(OOS_params$targetName)),
hor = OOS_params$horizon)
all_options <- expand.grid(combn)
all_options <- all_options[order(all_options$var,all_options$hor, decreasing = F),]
rownames(all_options) <- c()
set.seed(seed)
# Variable and Horizon to forecast #############################################################
# ==============================================================================================
#it_pos = 1
var <- all_options$var[it_pos]
# Variable and Horizon to forecast #############################################################
# ==============================================================================================
it_pos = 1
# Variable and Horizon to forecast #############################################################
# ==============================================================================================
#it_pos = 1
var <- all_options$var[it_pos]
hor <- all_options$hor[it_pos]
# Get the data
UKdata <- MakeDataUK(path = paste0(path,paths$dat,"/"), targetName = OOS_params$targetName[var], h = hor,
nFac = OOS_params$nFac, lag_y = OOS_params$lagY, lag_f = OOS_params$lagX, lag_marx = OOS_params$lagMARX,
versionName = "current",
download = F, EM_algorithm=F, EM_last_date=NA,
frequency = 1, target_new_tcode=OOS_params$target_tcode[var])
data <- UKdata[[1]]$lagged_data
# Parameters
H_max <- c(max(all_options$hor))
H <- unique(all_options$hor)
nfolds <- OOS_params$nfolds
reEstimate <- OOS_params$reEstimate
OOS_date <- OOS_params$OOS_starting_date
model_list <- OOS_params$model_list
lagY <- OOS_params$lagY
lagX <- OOS_params$lagX
nfac <- OOS_params$nFac
# Out of sample start
OOS <- nrow(data) - which(rownames(data) == OOS_date) + 1
# Random Forest a) hyperparameters
RF_hyps <<- OOS_params$RF_hyps
# Random Forest b) hyperparameters
RF_MAF_hyps <<- OOS_params$RF_MAF_hyps
# Macro Random Forest hyperparameters
MacroRF_hyps <<- OOS_params$MacroRF_hyps
# Macro Random Forest hyperparameters
FA_MacroRF_hyps <<- OOS_params$FA_MacroRF_hyps
## Storage -----------------------------------------------------------------------
#selected_H <- c("H3", "H12")
prediction_oos <- array(data = NA, dim = c(OOS, length(unique(all_options$var)), H_max, length(model_list)))
# Set the row names
rownames(prediction_oos) <- rownames(data)[c((length(rownames(data)) - OOS + 1):nrow(data))]
# prediction_oos <- array(data = NA, dim = c(OOS,length(unique(all_options$var)),H,length(model_list)))
#rownames(prediction_oos) <- rownames(data)[c((length(rownames(data))-OOS+1):nrow(data))]
dimnames(prediction_oos)[[2]] <- OOS_params$targetName
dimnames(prediction_oos)[[3]] <- paste0("H",1:H_max)
dimnames(prediction_oos)[[4]] <- model_list
err_oos <-  array(data = NA, dim = c(OOS,length(unique(all_options$var)),H_max,length(model_list)))
rownames(err_oos) <- rownames(data)[c((length(rownames(data))-OOS+1):nrow(data))]
dimnames(err_oos)[[2]] <-  OOS_params$targetName
dimnames(err_oos)[[3]] <- paste0("H",1:H_max)
dimnames(err_oos)[[4]] <- model_list
View(data)
# Find indices for columns 2 to 258
cols_2_714 <- 1:710
col_names <- colnames(newtrain)
# Find indices for columns containing '_F_UK'
cols_F_UK <- grep("_F_UK","trend", col_names)
# Combine the indices
selected_cols <- unique(c(cols_2_714, cols_F_UK))
selected_cols_1 <- selected_cols[-1]
# Find indices for columns 2 to 258
cols_2_714 <- 1:715
col_names <- colnames(newtrain)
# Find indices for columns containing '_F_UK'
cols_F_UK <- grep("_F_UK","trend", col_names)
# Combine the indices
selected_cols <- unique(c(cols_2_714, cols_F_UK))
