library(reshape2)   # Data manipulation
library(gridExtra)  # To organize results graphs
library(pracma)     # Utilities (for PCA)
library(stringr)    # String manipulation
library(doParallel) # Parallel estimation
library(foreach)    # Parallel estimation
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
# Factor analysis (PCA)
source(paste(paths$too, 'EM_sw.R', sep='/'))
source(paste(paths$too, 'factor.R', sep='/'))
source(paste(paths$too, 'ICp2.R', sep='/'))
MakeDataUK <- function(path, targetName, h, nFac, lag_y,lag_f, lag_marx, versionName="current", frequency, download=TRUE, EM_algorithm=T,
EM_last_date=NA,target_new_tcode) {
library(pracma)
library(stringr)
# path = paste0(path,paths$dat,"/")
# targetName = OOS_params$targetName[var]
# h = hor
#     nFac = OOS_params$nFac
#     lag_y = OOS_params$lagY
#     lag_f = OOS_params$lagX
#     lag_marx = OOS_params$lagMARX
# versionName = "current"
#
# download = F
# EM_algorithm=F
# EM_last_date=NA
#
# frequency = 1
#
# target_new_tcode=OOS_params$target_tcode[var]
# Download FRED-QD if needed
if(substr(path,nchar(path),nchar(path)) != "/") {path <- paste0(path,"/")}
# if(download == TRUE) {
#   if(frequency==1) {
#     url <- paste0("https://files.stlouisfed.org/files/htdocs/fred-md/monthly/",versionName,".csv")
#     download.file(url,
#                   destfile = paste(path,paste0(versionName,"_monthly.csv"),sep='/'),
#                   mode = "wb")
#   }else if(frequency==2) {
#     url <- paste0("https://files.stlouisfed.org/files/htdocs/fred-md/quarterly/",versionName,".csv")
#     download.file(url,
#                   destfile = paste(path,paste0(versionName,"_quarterly.csv"),sep='/'),
#                   mode = "wb")
#   }
#
# else {
#   local_path <- "C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/10_data/UKMD_April_2024"
#   if (frequency == 1) {
#     data <- read.csv(file.path(local_path, paste0("raw_uk_md.csv")))
#   }
#   return(data)
# }}
output <- vector("list", length = length(targetName))
# numOfTarget <-1
for (numOfTarget in 1:length(output)) {
# ## TRANSFORM DATA ---------------------------------------------------------------
# if(frequency==1){
#   data <- transformFRED(file = paste0(path,"raw_uk_md.csv"),date_start =as.Date("1998-01-01"), date_end = NULL,
#                         transform = TRUE, frequency, targetName[numOfTarget], target_new_tcode[numOfTarget], h)
# } else if(frequency==2){
#   data <- transformFRED(file = paste0(path,versionName,"_quarterly.csv"), date_start = NULL, date_end = NULL,
#                         transform = TRUE, frequency, targetName[numOfTarget], target_new_tcode[numOfTarget], h)
# }
local_path <- "C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/10_data/UKMD_April_2024"
if (frequency == 1) {
data <- read.csv(file.path(local_path, paste0("balanced_uk_md.csv")))
}
#
targetedSerie <- data[[targetName]]
# rawdata <- data[[2]]
# all_tcodes <- data[[4]]
# data <- data[[1]]
# transdata <- data
#
# Change variables names
# colnames(data)[grep(" ", colnames(data))] <- sub(" ",".",grep(" ", colnames(data), value = TRUE))
# colnames(data)[grep(" ", colnames(data))] <- sub(" ",".",grep(" ", colnames(data), value = TRUE))
# colnames(data)[grep("&", colnames(data))] <- sub("&",".",grep("&", colnames(data), value = TRUE))
# colnames(data)[grep(":", colnames(data))] <- sub(":","",grep(":", colnames(data), value = TRUE))
#
#
data <- data[,-1]
date <- as.character(data[,1])
if(length(targetedSerie)>1) {
names(targetedSerie) <- date
}
# Use EM Algorithm
# if(EM_algorithm == TRUE) {
#
#   if(!is.na(EM_last_date)) {
#     toUse <- 1:which(date == EM_last_date)
#     part <- EM_sw(data=data[toUse,], n=8, it_max=1000)$data
#     data <- rbind(part,as.matrix(data[-toUse,]))
#   }else{
#     data <- EM_sw(data=data[,], n=8, it_max=1000)$data
#   }
# }
# Get the target
rownames(data) <- date
target <- data[,which(colnames(data)==targetName[numOfTarget])]
if(length(targetedSerie)<2) {
targetedSerie <- target
}
data <- data[,-which(colnames(data)==targetName[numOfTarget])]
varNames <- colnames(data)
data <- data[1:313,-1] # drop 2024 because of NAs
target <- target[1:313]
#### LIBOR imputation
na_id <- which(is.na(data$LIBOR_3mth))
good_id <- sapply(na_id, function(x) x + -3:3)
imputation <- apply(good_id, 2, function(x) mean(data[x,"LIBOR_3mth"], na.rm = TRUE))
data[na_id,"LIBOR_3mth"] <- imputation
#
# data_m <- as.numeric(as.matrix(data))
# which(is.na(data_m))
######
X <- standard(as.matrix(data))
r <- nFac
bign <- dim(X)[2]
bigt <- dim(X)[1]
#X <- as.matrix(data)
#  t(data_m)%*%data_m
# data_m <- as.matrix()
test_xx <- t(X)%*%X
svd <- svd(test_xx)
# lambda <- svd$u[,1:r]*sqrt(bign) # r th column times r th biggest eigenvalue
# f_hat <- X%*%lambda/bign         # factors
# e_hat <- X - f_hat%*%t(lambda)   # errors
# mse <- sum(e_hat^2)/(bign*bigt)
#
# results <- list(factors = f_hat, lambda = lambda, mse = mse)
#
## MAKE FACTORS (if needed) -----------------------------------------------------
#
# data_s <- standard(data)
#
#
data_m <- as.matrix(data)
#
if(nFac > 0) {
facs <- factorize(standard((data_m))$Y, n_fac = nFac)$factor
colnames(facs) <- paste0("F_UK",1:nFac)
data = cbind(facs,data)
}else{
facs = NA
}
# factorize(as.matrix(test),n_fac=5)
## MAKE LAGS --------------------------------------------------------------------
maxLag <- max(lag_y, lag_f)
maxLag_marx = max(lag_marx)
maxLag_all = max(maxLag_marx,maxLag, na.rm = T)
newtrain <- make_reg_matrix(y=targetedSerie,Y=target,factors = data, h=h, max_y = lag_y+h-1, max_f = lag_f+h-1)
newtrain <- newtrain[(maxLag_all+h+1):nrow(newtrain),]
## MAKE MARX --------------------------------------------------------------------
if(!is.na(lag_marx)) {
if(nFac > 0) {
X_alt <- data[,-c(1:nFac)]
}else{
X_alt <- data
}
lags <- make_reg_matrix(y=targetedSerie,Y=target,factors = X_alt , h=h, max_y = maxLag_marx+h-1, max_f = maxLag_marx+h-1)
lags <- lags[(maxLag_all+h+1):nrow(lags),-c(1:(maxLag_marx+1))]
rownames(lags) <- c()
names.cs = colnames(X_alt)
bigX <- lags
names.bigX = 1:dim(bigX)[2]
lags_names <- paste0("L",0:(maxLag_marx-1),"_")
lags_names <- paste(lags_names, collapse = "|")
for(jj in 1:dim(bigX)[2]){
names.bigX[jj] = str_replace(colnames(bigX)[[jj]],lags_names,"")#substr(colnames(bigX)[jj],start=4,stop=nchar(colnames(bigX)[jj]))
}
new.facs = c()
new.marx <- c()
for(jj in 1:length(names.cs)){
subset=bigX[,names.bigX==names.cs[jj]]
marx <- do.call(cbind,
lapply(1:(maxLag_marx-1), function(x) (rowMeans(subset[,1:(x+1)]))) )
colnames(marx) <- paste0(paste0("L",1:(maxLag_marx-1),"_MARX"),"_",names.cs[jj])
new.marx <- cbind(new.marx,marx)
}
# MAF and MARX for Y
subset=newtrain[,2:(maxLag_marx+1)]
marx <- do.call(cbind,
lapply(1:(maxLag_marx-1), function(x) (rowMeans(subset[,1:(x+1)]))) )
colnames(marx) <- paste0(paste0("L",1:(maxLag_marx-1),"_MARX"),"_","YLag")
new.marx <- cbind(new.marx,marx)
# Keep only marx selected lags
# toKeep <- unlist(lapply(lag_marx, function(x) paste0("L",x-1,"_|")))
lag_marx_alt <- lag_marx[-length(lag_marx)]
toKeep <- paste0("L",lag_marx_alt-1,"_|")
toKeep <- paste(toKeep, collapse = '')
toKeep <- paste0(toKeep,"L",lag_marx[length(lag_marx)]-1,"_")
new.marx <- new.marx[,grep(toKeep, colnames(new.marx))]
newtrain <- cbind(newtrain,new.marx,trend=1:nrow(newtrain))
}else{
newtrain <- cbind(newtrain,trend=1:nrow(newtrain))
}
### COMBINE ALL ------------------------------------------------------------------
if(frequency==1) {
frequencyString = "Monthly"
}else if(frequency==2){
frequencyString = "Quarterly"
}
returns <- list(#trans_data=transdata,
#raw_data=rawdata,
lagged_data=newtrain,
factors=facs,
targetName=targetName[numOfTarget],
#  versionName=versionName,
horizon=h,
frequency=frequencyString,
varNames=c(varNames))
# tcodes=all_tcodes)
output[[numOfTarget]] <- returns
} #numOfTarget
names(output) <- targetName
return(output)
}
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
# Clear all
rm(list = ls())
set.seed(1234)
# Set paths
path <- 'C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/'
setwd(path)
paths <- list(pro = "00_prog",
dat = "10_data",
fig = "20_figures",
tab = "30_tables",
too = "40_tools",
rst = "50_results")
# Install needed packages
myPKGs <- c('torch', 'pracma','glmnet','ranger',
'ggplot2','reshape2', 'stringr','MacroRF',
'caret','doParallel','gridExtra','gbm')
InstalledPKGs <- names(installed.packages()[,'Package'])
InstallThesePKGs <- myPKGs[!myPKGs %in% InstalledPKGs]
if (length(InstallThesePKGs) > 0) install.packages(InstallThesePKGs, repos = "http://cran.us.r-project.org")
# Load libraries
library(torch)      # Neural Networks
library(glmnet)     # Lasso, Ridge and Elastic-Net
library(ranger)     # Random Forest
library(MacroRF)    # Macro Random Forest
library(caret)      # Gradient boosting machine (GBM)
library(ggplot2)    # Graphs
library(reshape2)   # Data manipulation
library(gridExtra)  # To organize results graphs
library(pracma)     # Utilities (for PCA)
library(stringr)    # String manipulation
library(doParallel) # Parallel estimation
library(foreach)    # Parallel estimation
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
path
paths$too
# Clear all
rm(list = ls())
set.seed(1234)
# Set paths
path <- 'C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/'
setwd(path)
paths <- list(pro = "00_prog",
dat = "10_data",
fig = "20_figures",
tab = "30_tables",
too = "40_tools",
rst = "50_results")
# Install needed packages
myPKGs <- c('torch', 'pracma','glmnet','ranger',
'ggplot2','reshape2', 'stringr','MacroRF',
'caret','doParallel','gridExtra','gbm')
InstalledPKGs <- names(installed.packages()[,'Package'])
InstallThesePKGs <- myPKGs[!myPKGs %in% InstalledPKGs]
if (length(InstallThesePKGs) > 0) install.packages(InstallThesePKGs, repos = "http://cran.us.r-project.org")
# Load libraries
library(torch)      # Neural Networks
library(glmnet)     # Lasso, Ridge and Elastic-Net
library(ranger)     # Random Forest
library(MacroRF)    # Macro Random Forest
library(caret)      # Gradient boosting machine (GBM)
library(ggplot2)    # Graphs
library(reshape2)   # Data manipulation
library(gridExtra)  # To organize results graphs
library(pracma)     # Utilities (for PCA)
library(stringr)    # String manipulation
library(doParallel) # Parallel estimation
library(foreach)    # Parallel estimation
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
paste(paths$too, 'MakeDataUK_function.R', sep='/')
getwd()
MakeDataUK <- function(path, targetName, h, nFac, lag_y,lag_f, lag_marx, versionName="current", frequency, download=TRUE, EM_algorithm=T,
EM_last_date=NA,target_new_tcode) {
library(pracma)
library(stringr)
# path = paste0(path,paths$dat,"/")
# targetName = OOS_params$targetName[var]
# h = hor
#     nFac = OOS_params$nFac
#     lag_y = OOS_params$lagY
#     lag_f = OOS_params$lagX
#     lag_marx = OOS_params$lagMARX
# versionName = "current"
#
# download = F
# EM_algorithm=F
# EM_last_date=NA
#
# frequency = 1
#
# target_new_tcode=OOS_params$target_tcode[var]
# Download FRED-QD if needed
if(substr(path,nchar(path),nchar(path)) != "/") {path <- paste0(path,"/")}
# if(download == TRUE) {
#   if(frequency==1) {
#     url <- paste0("https://files.stlouisfed.org/files/htdocs/fred-md/monthly/",versionName,".csv")
#     download.file(url,
#                   destfile = paste(path,paste0(versionName,"_monthly.csv"),sep='/'),
#                   mode = "wb")
#   }else if(frequency==2) {
#     url <- paste0("https://files.stlouisfed.org/files/htdocs/fred-md/quarterly/",versionName,".csv")
#     download.file(url,
#                   destfile = paste(path,paste0(versionName,"_quarterly.csv"),sep='/'),
#                   mode = "wb")
#   }
#
# else {
#   local_path <- "C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/10_data/UKMD_April_2024"
#   if (frequency == 1) {
#     data <- read.csv(file.path(local_path, paste0("raw_uk_md.csv")))
#   }
#   return(data)
# }}
output <- vector("list", length = length(targetName))
# numOfTarget <-1
for (numOfTarget in 1:length(output)) {
# ## TRANSFORM DATA ---------------------------------------------------------------
# if(frequency==1){
#   data <- transformFRED(file = paste0(path,"raw_uk_md.csv"),date_start =as.Date("1998-01-01"), date_end = NULL,
#                         transform = TRUE, frequency, targetName[numOfTarget], target_new_tcode[numOfTarget], h)
# } else if(frequency==2){
#   data <- transformFRED(file = paste0(path,versionName,"_quarterly.csv"), date_start = NULL, date_end = NULL,
#                         transform = TRUE, frequency, targetName[numOfTarget], target_new_tcode[numOfTarget], h)
# }
local_path <- "C:/Users/avalder/OneDrive - WU Wien/Documents/Study/SoSe_24/Statistical Learning/assignments/StatL_5454/project/empirical/10_data/UKMD_April_2024"
if (frequency == 1) {
data <- read.csv(file.path(local_path, paste0("balanced_uk_md.csv")))
}
#
targetedSerie <- data[[targetName]]
# rawdata <- data[[2]]
# all_tcodes <- data[[4]]
# data <- data[[1]]
# transdata <- data
#
# Change variables names
# colnames(data)[grep(" ", colnames(data))] <- sub(" ",".",grep(" ", colnames(data), value = TRUE))
# colnames(data)[grep(" ", colnames(data))] <- sub(" ",".",grep(" ", colnames(data), value = TRUE))
# colnames(data)[grep("&", colnames(data))] <- sub("&",".",grep("&", colnames(data), value = TRUE))
# colnames(data)[grep(":", colnames(data))] <- sub(":","",grep(":", colnames(data), value = TRUE))
#
#
data <- data[,-1]
date <- as.character(data[,1])
if(length(targetedSerie)>1) {
names(targetedSerie) <- date
}
# Use EM Algorithm
# if(EM_algorithm == TRUE) {
#
#   if(!is.na(EM_last_date)) {
#     toUse <- 1:which(date == EM_last_date)
#     part <- EM_sw(data=data[toUse,], n=8, it_max=1000)$data
#     data <- rbind(part,as.matrix(data[-toUse,]))
#   }else{
#     data <- EM_sw(data=data[,], n=8, it_max=1000)$data
#   }
# }
# Get the target
rownames(data) <- date
target <- data[,which(colnames(data)==targetName[numOfTarget])]
if(length(targetedSerie)<2) {
targetedSerie <- target
}
data <- data[,-which(colnames(data)==targetName[numOfTarget])]
varNames <- colnames(data)
data <- data[1:313,-1] # drop 2024 because of NAs
target <- target[1:313]
#### LIBOR imputation
na_id <- which(is.na(data$LIBOR_3mth))
good_id <- sapply(na_id, function(x) x + -3:3)
imputation <- apply(good_id, 2, function(x) mean(data[x,"LIBOR_3mth"], na.rm = TRUE))
data[na_id,"LIBOR_3mth"] <- imputation
#
# data_m <- as.numeric(as.matrix(data))
# which(is.na(data_m))
######
X <- standard(as.matrix(data))
r <- nFac
bign <- dim(X)[2]
bigt <- dim(X)[1]
#X <- as.matrix(data)
#  t(data_m)%*%data_m
# data_m <- as.matrix()
test_xx <- t(X)%*%X
svd <- svd(test_xx)
# lambda <- svd$u[,1:r]*sqrt(bign) # r th column times r th biggest eigenvalue
# f_hat <- X%*%lambda/bign         # factors
# e_hat <- X - f_hat%*%t(lambda)   # errors
# mse <- sum(e_hat^2)/(bign*bigt)
#
# results <- list(factors = f_hat, lambda = lambda, mse = mse)
#
## MAKE FACTORS (if needed) -----------------------------------------------------
#
# data_s <- standard(data)
#
#
data_m <- as.matrix(data)
#
if(nFac > 0) {
facs <- factorize(standard((data_m))$Y, n_fac = nFac)$factor
colnames(facs) <- paste0("F_UK",1:nFac)
data = cbind(facs,data)
}else{
facs = NA
}
# factorize(as.matrix(test),n_fac=5)
## MAKE LAGS --------------------------------------------------------------------
maxLag <- max(lag_y, lag_f)
maxLag_marx = max(lag_marx)
maxLag_all = max(maxLag_marx,maxLag, na.rm = T)
newtrain <- make_reg_matrix(y=targetedSerie,Y=target,factors = data, h=h, max_y = lag_y+h-1, max_f = lag_f+h-1)
newtrain <- newtrain[(maxLag_all+h+1):nrow(newtrain),]
## MAKE MARX --------------------------------------------------------------------
if(!is.na(lag_marx)) {
if(nFac > 0) {
X_alt <- data[,-c(1:nFac)]
}else{
X_alt <- data
}
lags <- make_reg_matrix(y=targetedSerie,Y=target,factors = X_alt , h=h, max_y = maxLag_marx+h-1, max_f = maxLag_marx+h-1)
lags <- lags[(maxLag_all+h+1):nrow(lags),-c(1:(maxLag_marx+1))]
rownames(lags) <- c()
names.cs = colnames(X_alt)
bigX <- lags
names.bigX = 1:dim(bigX)[2]
lags_names <- paste0("L",0:(maxLag_marx-1),"_")
lags_names <- paste(lags_names, collapse = "|")
for(jj in 1:dim(bigX)[2]){
names.bigX[jj] = str_replace(colnames(bigX)[[jj]],lags_names,"")#substr(colnames(bigX)[jj],start=4,stop=nchar(colnames(bigX)[jj]))
}
new.facs = c()
new.marx <- c()
for(jj in 1:length(names.cs)){
subset=bigX[,names.bigX==names.cs[jj]]
marx <- do.call(cbind,
lapply(1:(maxLag_marx-1), function(x) (rowMeans(subset[,1:(x+1)]))) )
colnames(marx) <- paste0(paste0("L",1:(maxLag_marx-1),"_MARX"),"_",names.cs[jj])
new.marx <- cbind(new.marx,marx)
}
# MAF and MARX for Y
subset=newtrain[,2:(maxLag_marx+1)]
marx <- do.call(cbind,
lapply(1:(maxLag_marx-1), function(x) (rowMeans(subset[,1:(x+1)]))) )
colnames(marx) <- paste0(paste0("L",1:(maxLag_marx-1),"_MARX"),"_","YLag")
new.marx <- cbind(new.marx,marx)
# Keep only marx selected lags
# toKeep <- unlist(lapply(lag_marx, function(x) paste0("L",x-1,"_|")))
lag_marx_alt <- lag_marx[-length(lag_marx)]
toKeep <- paste0("L",lag_marx_alt-1,"_|")
toKeep <- paste(toKeep, collapse = '')
toKeep <- paste0(toKeep,"L",lag_marx[length(lag_marx)]-1,"_")
new.marx <- new.marx[,grep(toKeep, colnames(new.marx))]
newtrain <- cbind(newtrain,new.marx,trend=1:nrow(newtrain))
}else{
newtrain <- cbind(newtrain,trend=1:nrow(newtrain))
}
### COMBINE ALL ------------------------------------------------------------------
if(frequency==1) {
frequencyString = "Monthly"
}else if(frequency==2){
frequencyString = "Quarterly"
}
returns <- list(#trans_data=transdata,
#raw_data=rawdata,
lagged_data=newtrain,
factors=facs,
targetName=targetName[numOfTarget],
#  versionName=versionName,
horizon=h,
frequency=frequencyString,
varNames=c(varNames))
# tcodes=all_tcodes)
output[[numOfTarget]] <- returns
} #numOfTarget
names(output) <- targetName
return(output)
}
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
# Target names from FRED DB
OOS_params$targetName <- c("IOP_PROD","CPIAUCSL")[1]
## OOS Parameters ----------------------------------------------------------------
OOS_params <- list()
# Target names from FRED DB
OOS_params$targetName <- c("IOP_PROD","CPIAUCSL")[1]
# Load US data retreiver
source(paste(paths$too, 'MakeDataUK_function.R', sep='/'))
