torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_test_1h), dtype = torch_float()),
torch_tensor(unlist(test$y), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
#https://www.casact.org/sites/default/files/2022-12/James-G.-et-al.-2nd-edition-Springer-2021.pdf
library(torch)
library(torchdatasets)
library(luz)
set.seed(1)
max_features <- 50
imdb_train <- imdb_dataset(
root = ".",
download = TRUE,
split="train",
num_words = max_features
)
imdb_train <- imdb_dataset(
root = ".",
download = TRUE,
split="train",
num_words = max_features
)
imdb_test <- imdb_dataset(
root = ".",
download = TRUE,
split="test",
num_words = max_features
)
imdb_train[1]$x[1:12]
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 50 + 3) # chnage
x_test_1h <- one_hot(test$x, 50 + 3)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 50 + 3) { # chnage!!
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 500 + 3) { # chnage!!
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
imdb_train[1]$x[1:12]
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
# collect all values into a list
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
# collect all values into a list
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 10000 + 3)
x_test_1h <- one_hot(test$x, 10000 + 3)
dim(x_train_1h)
set.seed(3)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 10000 + 3) {
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
#https://www.casact.org/sites/default/files/2022-12/James-G.-et-al.-2nd-edition-Springer-2021.pdf
library(torch)
#https://www.casact.org/sites/default/files/2022-12/James-G.-et-al.-2nd-edition-Springer-2021.pdf
library(torch)
library(torchdatasets)
#https://www.casact.org/sites/default/files/2022-12/James-G.-et-al.-2nd-edition-Springer-2021.pdf
library(torch)
library(torchdatasets)
library(luz)
set.seed(1)
max_features <- 1000
imdb_train <- imdb_dataset(
root = ".",
download = TRUE,
split="train",
num_words = max_features
)
imdb_test <- imdb_dataset(
root = ".",
download = TRUE,
split="test",
num_words = max_features
)
imdb_train[1]$x[1:12]
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
# collect all values into a list
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
# collect all values into a list
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 1000 + 3)
x_test_1h <- one_hot(test$x, 1000 + 3)
dim(x_train_1h)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
set.seed(3)
ival <- sample(seq(along = train$y), 200)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 1000 + 3) {
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
plot(fitted)
# Fit the model with test data as validation data to get test accuracy
fitted_test <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_test_1h), dtype = torch_float()),
torch_tensor(unlist(test$y), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
# Fit the model with test data as validation data to get test accuracy
fitted_test <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_test_1h), dtype = torch_float()),
torch_tensor(unlist(test$y), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
plot(fitted_test)
# Helper function to extract metrics
extract_metric <- function(metric_list, metric_name) {
sapply(metric_list, function(epoch) epoch[[metric_name]])}
# Extract metrics
train_loss <- extract_metric(fitted$records$metrics$train, "loss")
val_loss <- extract_metric(fitted$records$metrics$valid, "loss")
test_loss <- extract_metric(fitted_test$records$metrics$valid, "loss")
train_acc <- extract_metric(fitted$records$metrics$train, "acc")
val_acc <- extract_metric(fitted$records$metrics$valid, "acc")
test_acc <- extract_metric(fitted_test$records$metrics$valid, "acc")
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:20, 3),
Metric = c(rep("Train", 20), rep("Validation", 20), rep("Test", 20)),
Loss = c(train_loss, val_loss, rep(NA, 20)),
Accuracy = c(train_acc, val_acc, test_acc)
)
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:10, 3),
Metric = c(rep("Train", 20), rep("Validation", 20), rep("Test", 20)),
Loss = c(train_loss, val_loss, rep(NA, 20)),
Accuracy = c(train_acc, val_acc, test_acc)
)
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:10, 3),
Metric = c(rep("Train", 10), rep("Validation", 10), rep("Test", 10)),
Loss = c(train_loss, val_loss, rep(NA, 10)),
Accuracy = c(train_acc, val_acc, test_acc)
)
# Plotting the results
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Loss, color = Metric), na.rm = TRUE) +
labs(y = "Loss") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Loss per Epoch")
library(ggplot2)
# Plotting the results
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Loss, color = Metric), na.rm = TRUE) +
labs(y = "Loss") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Loss per Epoch")
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Accuracy, color = Metric)) +
labs(y = "Accuracy") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Accuracy per Epoch")
plot(fitted_test)
# Plotting the results
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Loss, color = Metric), na.rm = TRUE) +
labs(y = "Loss") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Loss per Epoch")
View(df)
test_loss <- extract_metric(fitted_test$records$metrics$valid, "loss")
train_acc <- extract_metric(fitted$records$metrics$train, "acc")
val_acc <- extract_metric(fitted$records$metrics$valid, "acc")
test_acc <- extract_metric(fitted_test$records$metrics$valid, "acc")
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:10, 3),
Metric = c(rep("Train", 10), rep("Validation", 10), rep("Test", 10)),
Loss = c(train_loss, val_loss, rep(NA, 10)),
Accuracy = c(train_acc, val_acc, test_acc)
)
library(ggplot2)
# Plotting the results
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Loss, color = Metric), na.rm = TRUE) +
labs(y = "Loss") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Loss per Epoch")
View(df)
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:10, 3),
Metric = c(rep("Train", 10), rep("Validation", 10), rep("Test", 10)),
Loss = c(train_loss, val_loss, test_acc),
Accuracy = c(train_acc, val_acc, test_acc)
)
library(ggplot2)
# Plotting the results
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Loss, color = Metric), na.rm = TRUE) +
labs(y = "Loss") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Loss per Epoch")
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:10, 3),
Metric = c(rep("Train", 10), rep("Validation", 10), rep("Test", 10)),
Loss = c(train_loss, val_loss, test_loss),
Accuracy = c(train_acc, val_acc, test_acc)
)
library(ggplot2)
# Plotting the results
ggplot(df, aes(x = Epoch)) +
geom_line(aes(y = Loss, color = Metric), na.rm = TRUE) +
labs(y = "Loss") +
scale_color_manual(values = c("blue", "red", "orange")) +
theme_minimal() +
ggtitle("Loss per Epoch")
p <-plot(fitted_test)
p <-plot(fitted_test)
# Helper function to extract metrics
extract_metric <- function(metric_list, metric_name) {
sapply(metric_list, function(epoch) epoch[[metric_name]])}
p
gen_path<-"~/"  #Specific to the computer
path
gen_path
getwd()
f <- 500
dictionary <- as.character(f)
wd_output <-paste(path,dictionary,sep="")
path <- paste(gen_path,"Ex5/",sep="") #Relative to gen path
wd_output <-paste(path,dictionary,sep="")
wd_dictionary <-paste(path,dictionary,sep="")
wd_dictionary
f <- 500
dictionary <- as.character(f)
wd_dictionary <-paste(path,dictionary,sep="")
setwd(wd_dictionary)
