extract_metric <- function(metric_list, metric_name) {
sapply(metric_list, function(epoch) epoch[[metric_name]])}
# Extract metrics
train_loss <- extract_metric(fitted$records$metrics$train_loss, "loss")
val_loss <- extract_metric(fitted$records$metrics$valid_loss, "loss")
train_acc <- extract_metric(fitted$records$metrics$train_binary_accuracy_with_logits, "acc")
val_acc <- extract_metric(fitted$records$metrics$valid_binary_accuracy_with_logits, "acc")
test_acc <- extract_metric(fitted_test$records$metrics$valid_binary_accuracy_with_logits, "acc")
# Extract metrics
train_loss <- extract_metric(fitted$records$metrics$train_loss, "loss")
val_loss <- extract_metric(fitted$records$metrics$valid_loss, "loss")
test_loss <- extract_metric(fitted_test$records$metrics$valid_loss, "loss")
train_acc <- extract_metric(fitted$records$metrics$train_binary_accuracy_with_logits, "acc")
val_acc <- extract_metric(fitted$records$metrics$valid_binary_accuracy_with_logits, "acc")
test_acc <- extract_metric(fitted_test$records$metrics$valid_binary_accuracy_with_logits, "acc")
# Extract metrics
train_mtr <- fitted$records$metrics$train
# Create data frame for plotting
df <- data.frame(
Epoch = rep(1:20, 3),
Metric = c(rep("Train", 20), rep("Validation", 20), rep("Test", 20)),
Loss = c(train_loss, val_loss, rep(NA, 20)),
Accuracy = c(train_acc, val_acc, test_acc)
)
# Extract metrics
train_loss <- extract_metric(fitted$records$metrics$train, "loss")
# Helper function to extract metrics
extract_metric <- function(metric_list, metric_name) {
sapply(metric_list, function(epoch) epoch[[metric_name]])}
# Extract metrics
train_loss <- extract_metric(fitted$records$metrics$train, "loss")
```{r}
# num_words + padding + start + oov token = 500 + 3
x_train_1h <- one_hot(train$x, max_features + 3)
x_test_1h <- one_hot(test$x, max_features + 3)
x_test_1h <- one_hot(test$x, max_features + 3)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
# Define the model
model <- nn_module(
initialize = function(input_size = max_features + 3) {
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 20
)
set.seed(1)
max_features <- 500
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
# Define the model
model <- nn_module(
initialize = function(input_size = max_features + 3) {
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 20
)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 20
)
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
# Define the model
model <- nn_module(
initialize = function(input_size = max_features + 3) {
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
# Fit the model with test data as validation data to get test accuracy
fitted_test <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_test_1h), dtype = torch_float()),
torch_tensor(unlist(test$y), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
#https://www.casact.org/sites/default/files/2022-12/James-G.-et-al.-2nd-edition-Springer-2021.pdf
library(torch)
library(torchdatasets)
library(luz)
set.seed(1)
max_features <- 50
imdb_train <- imdb_dataset(
root = ".",
download = TRUE,
split="train",
num_words = max_features
)
imdb_train <- imdb_dataset(
root = ".",
download = TRUE,
split="train",
num_words = max_features
)
imdb_test <- imdb_dataset(
root = ".",
download = TRUE,
split="test",
num_words = max_features
)
imdb_train[1]$x[1:12]
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 50 + 3) # chnage
x_test_1h <- one_hot(test$x, 50 + 3)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 50 + 3) { # chnage!!
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
# Fit the model with training and validation data
fitted <- model %>%
fit(
list(
torch_tensor(as.matrix(x_train_1h[itrain, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]), dtype = torch_float())
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]), dtype = torch_float())
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 500 + 3) # chnage
x_test_1h <- one_hot(test$x, 500 + 3)
x_test_1h <- one_hot(test$x, 500 + 3)
dim(x_train_1h)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 500 + 3) { # chnage!!
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
imdb_train[1]$x[1:12]
library(Matrix)
one_hot <- function(sequences, dimension) {
seqlen <- sapply(sequences, length)
n <- length(seqlen)
rowind <- rep(1:n, seqlen)
colind <- unlist(sequences)
sparseMatrix(i = rowind, j = colind,
dims = c(n, dimension))
}
# collect all values into a list
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
# collect all values into a list
train <- seq_along(imdb_train) %>%
lapply(function(i) imdb_train[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
test <- seq_along(imdb_test) %>%
lapply(function(i) imdb_test[i]) %>%
purrr::transpose()
# num_words + padding + start + oov token = 10000 + 3
x_train_1h <- one_hot(train$x, 10000 + 3)
x_test_1h <- one_hot(test$x, 10000 + 3)
dim(x_train_1h)
set.seed(3)
set.seed(3)
ival <- sample(seq(along = train$y), 2000)
itrain <- seq_along(train$y)[-ival]
model <- nn_module(
initialize = function(input_size = 10000 + 3) {
self$dense1 <- nn_linear(input_size, 16)
self$relu <- nn_relu()
self$dense2 <- nn_linear(16, 16)
self$output <- nn_linear(16, 1)
},
forward = function(x) {
x %>%
self$dense1() %>%
self$relu() %>%
self$dense2() %>%
self$relu() %>%
self$output() %>%
torch_flatten(start_dim = 1)
}
)
model <- model %>%
setup(
loss = nn_bce_with_logits_loss(),
optimizer = optim_rmsprop,
metrics = list(luz_metric_binary_accuracy_with_logits())
) %>%
set_opt_hparams(lr = 0.001)
fitted <- model %>%
fit(
# we transform the training and validation data into torch tensors
list(
torch_tensor(as.matrix(x_train_1h[itrain,]), dtype = torch_float()),
torch_tensor(unlist(train$y[itrain]))
),
valid_data = list(
torch_tensor(as.matrix(x_train_1h[ival, ]), dtype = torch_float()),
torch_tensor(unlist(train$y[ival]))
),
dataloader_options = list(batch_size = 512),
epochs = 10
)
